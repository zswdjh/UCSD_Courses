{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import urllib.request\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "def parseData(fname):\n",
    "    for l in urllib.request.urlopen(fname):\n",
    "        yield eval(l)\n",
    "print (\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse258/data/beer/beer_50000.json\"))[:5000]\n",
    "print (\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of unique bigrams are:  176685\n",
      "the 5 most frequently-occurring bigrams are :\n",
      "(('with', 'a'), 4586)\n",
      "(('in', 'the'), 2593)\n",
      "(('of', 'the'), 2243)\n",
      "(('is', 'a'), 2053)\n",
      "(('on', 'the'), 2031)\n"
     ]
    }
   ],
   "source": [
    "#problem 1\n",
    "punctuation = set(string.punctuation)\n",
    "review = []\n",
    "for d in data:\n",
    "    per_review = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    review.append(per_review.split('\\t'))\n",
    "sentence = []\n",
    "for d in review:\n",
    "    for i in d:\n",
    "        if i != '' and len(i)>1:\n",
    "            sentence.append(i)\n",
    "bigrams = [b for d in sentence for b in zip(d.split(' ')[:-1],d.split(' ')[1:])]   \n",
    "bigrams_count = defaultdict(int)\n",
    "for i in bigrams:\n",
    "    bigrams_count[i] += 1\n",
    "import operator\n",
    "sorted_bc = sorted(bigrams_count.items(),key = operator.itemgetter(1),reverse = True)\n",
    "print('the number of unique bigrams are: ',len(sorted_bc))\n",
    "print('the 5 most frequently-occurring bigrams are :' )\n",
    "for i in range(5):\n",
    "      print(sorted_bc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#or sorting using this code:\n",
    "counts = [(bigrams_count[w],w) for w in bigrams_count]\n",
    "counts.sort()\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#problem 2\n",
    "bigram_1000 = [x[1] for x in counts[:1000]]\n",
    "wordID = dict(zip(bigram_1000,range(len(bigram_1000))))\n",
    "def feature(datum):\n",
    "    feat = [0]*len(bigram_1000)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    review_without_t = r.split('\\t')\n",
    "    sentence1 = []\n",
    "    for i in review_without_t:\n",
    "        if i != '' and len(i)>1:\n",
    "            sentence1.append(i)\n",
    "    bigram_sentence = [b for d in sentence1 for b in zip(d.split(' ')[:-1],d.split(' ')[1:])]  \n",
    "    for b in bigram_sentence:\n",
    "        if b in bigram_1000:\n",
    "            feat[wordID[b]] +=1\n",
    "    feat.append(1)\n",
    "    return feat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for using 1000 most common bigrams is:  1.16956086931e-05\n"
     ]
    }
   ],
   "source": [
    "X = [feature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "clf = linear_model.Ridge(1.0,fit_intercept = False)\n",
    "clf.fit(X,y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "MSE = 0\n",
    "for i in range(len(y)):\n",
    "    MSE = (y[i]-predictions[i])**2\n",
    "MSE = MSE/len(y)\n",
    "print('MSE for using 1000 most common bigrams is: ',MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#problem 3\n",
    "#using 50% most popular in unigram model and 50% in bigram model\n",
    "wordCount = defaultdict(int)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordCount[w] +=1\n",
    "counts_uni = [(wordCount[w],w) for w in wordCount]\n",
    "counts_uni.sort()\n",
    "counts_uni.reverse()\n",
    "unigram_1000 = [x[1] for x in counts_uni[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_popular = unigram_1000[:500]+bigram_1000[:500]\n",
    "new_wordID = dict(zip(new_popular,range(len(bigram_1000))))\n",
    "def newfeature(datum):\n",
    "    feat = [0]*len(new_wordID)\n",
    "    #deal with unigram\n",
    "    ru = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "    for w in ru.split():\n",
    "        if w in new_popular:\n",
    "            feat[new_wordID[w]] +=1\n",
    "    #deal with bigram\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    review_without_t = r.split('\\t')\n",
    "    sentence1 = []\n",
    "    for i in review_without_t:\n",
    "        if i != '' and len(i)>1:\n",
    "            sentence1.append(i)\n",
    "    bigram_sentence = [b for d in sentence1 for b in zip(d.split(' ')[:-1],d.split(' ')[1:])]  \n",
    "    for b in bigram_sentence:\n",
    "        if b in new_popular:\n",
    "            feat[new_wordID[b]] +=1\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for using 1000 combination feature is:  4.16148936278e-05\n"
     ]
    }
   ],
   "source": [
    "X = [newfeature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "clf = linear_model.Ridge(1.0,fit_intercept = False)\n",
    "clf.fit(X,y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "MSE = 0\n",
    "for i in range(len(y)):\n",
    "    MSE = (y[i]-predictions[i])**2\n",
    "MSE = MSE/len(y)\n",
    "print('MSE for using 1000 combination feature is: ',MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_popular1 = new_popular\n",
    "new_popular1.append('constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_popular1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0050679966809737556, 'constant')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#problem 4\n",
    "#0-499 unigram model   #500-999 bigram model\n",
    "theta = list(theta)\n",
    "index = list(zip(theta,new_popular1))\n",
    "sorted_index = sorted(index, key=lambda tup: tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 unigrams/bigrams with most negative associated weights: \n",
      "unigram/bigram is : ('at', 'a') weight is : -0.258264193984\n",
      "unigram/bigram is : ('a', 'pale') weight is : -0.212990993127\n",
      "unigram/bigram is : ('tastes', 'like') weight is : -0.205865954323\n",
      "unigram/bigram is : ('sort', 'of') weight is : -0.190997816898\n",
      "unigram/bigram is : ('the', 'bitterness') weight is : -0.177478809295\n"
     ]
    }
   ],
   "source": [
    "print('5 unigrams/bigrams with most negative associated weights: ')\n",
    "for i in range(5):\n",
    "    print('unigram/bigram is :',sorted_index[i][1],'weight is :',sorted_index[i][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 unigrams/bigrams with most positive associated weights: \n",
      "unigram/bigram is : ('very', 'drinkable') weight is : 0.286631586356\n",
      "unigram/bigram is : ('i', 'love') weight is : 0.253146868245\n",
      "unigram/bigram is : ('the', 'best') weight is : 0.241321052988\n",
      "unigram/bigram is : ('easy', 'to') weight is : 0.231415813322\n",
      "unigram/bigram is : ('up', 'a') weight is : 0.203191599824\n"
     ]
    }
   ],
   "source": [
    "sorted_again = sorted(index, key=lambda tup: tup[0],reverse = True)\n",
    "print('5 unigrams/bigrams with most positive associated weights: ')\n",
    "for i in range(5):\n",
    "    print('unigram/bigram is :',sorted_again[i][1],'weight is :',sorted_again[i][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 5\n",
    "def count(w):\n",
    "    final_count = 0\n",
    "    for d in data:\n",
    "        r = ''.join([c for c in d['review/text'].lower() if not c in punctuation])\n",
    "        if w in r.split():\n",
    "            final_count += 1\n",
    "    return final_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "N=5000\n",
    "df_foam = count('foam')\n",
    "df_smell = count('smell')\n",
    "df_banana = count('banana')\n",
    "df_lactic = count('lactic')\n",
    "df_tart = count('tart')\n",
    "idf_foam = log10(N/df_foam)\n",
    "idf_smell = log10(N/df_smell)\n",
    "idf_banana = log10(N/df_banana)\n",
    "idf_lactic = log10(N/df_lactic)\n",
    "idf_tart = log10(N/df_tart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the inverse document frequency of word foam   is:  1.1378686206869628\n",
      "the inverse document frequency of word smell  is:  0.5379016188648442\n",
      "the inverse document frequency of word banana is:  1.6777807052660807\n",
      "the inverse document frequency of word lactic is:  2.9208187539523753\n",
      "the inverse document frequency of word tart   is:  1.8068754016455384\n"
     ]
    }
   ],
   "source": [
    "print('the inverse document frequency of word foam   is: ',idf_foam)\n",
    "print('the inverse document frequency of word smell  is: ',idf_smell)\n",
    "print('the inverse document frequency of word banana is: ',idf_banana)\n",
    "print('the inverse document frequency of word lactic is: ',idf_lactic)\n",
    "print('the inverse document frequency of word tart   is: ',idf_tart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(w):\n",
    "    r = ''.join([c for c in data[0]['review/text'].lower() if not c in punctuation])\n",
    "    result = r.split().count(w)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf score of word foam in the first review is   : 2.2757372413739256\n",
      "tf-idf score of word smell in the first review is  : 0.5379016188648442\n",
      "tf-idf score of word banana in the first review is : 3.3555614105321614\n",
      "tf-idf score of word lactic in the first review is : 5.841637507904751\n",
      "tf-idf score of word tart in the first review is   : 1.8068754016455384\n"
     ]
    }
   ],
   "source": [
    "tf_foam = tf('foam')\n",
    "tf_smell = tf('smell')\n",
    "tf_banana = tf('banana')\n",
    "tf_lactic = tf('lactic')\n",
    "tf_tart = tf('tart')\n",
    "tfidf_foam = tf_foam*idf_foam\n",
    "tfidf_smell = tf_smell*idf_smell\n",
    "tfidf_banana = tf_banana*idf_banana\n",
    "tfidf_lactic = tf_lactic*idf_lactic\n",
    "tfidf_tart = tf_tart*idf_tart\n",
    "print('tf-idf score of word foam in the first review is   :',tfidf_foam)\n",
    "print('tf-idf score of word smell in the first review is  :',tfidf_smell)\n",
    "print('tf-idf score of word banana in the first review is :',tfidf_banana)\n",
    "print('tf-idf score of word lactic in the first review is :',tfidf_lactic)\n",
    "print('tf-idf score of word tart in the first review is   :',tfidf_tart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 6\n",
    "unigramID = dict(zip(range(len(unigram_1000)),unigram_1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcount1 = defaultdict(int)  #word shows in review 1 and corresponding times\n",
    "r = ''.join([c for c in data[0]['review/text'].lower() if not c in punctuation])\n",
    "for w in r.split():\n",
    "    wordcount1[w] += 1\n",
    "wordcount2 = defaultdict(int)\n",
    "r = ''.join([c for c in data[1]['review/text'].lower() if not c in punctuation])\n",
    "for w in r.split():\n",
    "    wordcount2[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in_1 = [w for w in wordcount1]\n",
    "word_in_2 = [w for w in wordcount2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = []\n",
    "for i in range(1000):\n",
    "    word = unigramID[i]\n",
    "    if word in word_in_1:\n",
    "        tf1.append(wordcount1[word])\n",
    "    else:\n",
    "        tf1.append(0)\n",
    "tf2 = []\n",
    "for i in range(1000):\n",
    "    word = unigramID[i]\n",
    "    if word in word_in_2:\n",
    "        tf2.append(wordcount2[word])\n",
    "    else:\n",
    "        tf2.append(0)\n",
    "idf1 = []\n",
    "for i in range(1000):\n",
    "    word = unigramID[i]\n",
    "    if word in word_in_1:\n",
    "        idf = log10(N/count(word))\n",
    "        idf1.append(idf)\n",
    "    else:\n",
    "        idf1.append(0)\n",
    "idf2 = []\n",
    "for i in range(1000):\n",
    "    word = unigramID[i]\n",
    "    if word in word_in_2:\n",
    "        idf = log10(N/count(word))\n",
    "        idf2.append(idf)\n",
    "    else:\n",
    "        idf2.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_theta =  0.106130241679  theta =  0.466153952679 pi\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tfidf1 = np.array(tf1)*np.array(idf1)\n",
    "tfidf2 = np.array(tf2)*np.array(idf2)\n",
    "tfidf1_list = tfidf1.tolist()\n",
    "tfidf2_list = tfidf2.tolist()\n",
    "sum1 = 0\n",
    "for i in tfidf1_list:\n",
    "    sum1 += i**2\n",
    "sum1 = sum1**(0.5)\n",
    "sum2 = 0\n",
    "for i in tfidf2_list:\n",
    "    sum2 += i**2\n",
    "sum2 = sum2**(0.5)\n",
    "from math import pi\n",
    "cos = np.dot(tfidf1_list,tfidf2_list)/(sum1*sum2)\n",
    "angle = np.arccos(cos)\n",
    "print('cos_theta = ',cos,' theta = ',angle/pi,'pi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 7\n",
    "unigramID = dict(zip(range(len(unigram_1000)),unigram_1000))\n",
    "word_ID = dict(zip(unigram_1000,range(len(unigram_1000))))\n",
    "idf_unigram1000 = [0]*1000\n",
    "for word in unigram_1000:\n",
    "    index = word_ID[word]\n",
    "    idf_unigram1000[index] = log10(5000/count(word))  #calculate the idf for 1000 popular unigrams\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_tfidf(datum):\n",
    "    wordcount = defaultdict(int)  #word shows in review 1 and corresponding times\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        wordcount[w] += 1\n",
    "    tf = [0]*1000\n",
    "    idf_value = [0]*1000\n",
    "    for word in wordcount:\n",
    "        if word in unigram_1000:\n",
    "            index = word_ID[word]\n",
    "            tf[index] = wordcount[word]\n",
    "            idf_value[index] = idf_unigram1000[index]\n",
    "        else:\n",
    "            continue\n",
    "    tfidf = np.array(tf)*np.array(idf_value)\n",
    "    tfidf_list = tfidf.tolist()\n",
    "    return tfidf_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = [calculate_tfidf(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = []\n",
    "for i in tfidf:\n",
    "    sum_value = np.dot(i,i)\n",
    "    sum_value = sum_value**(0.5)\n",
    "    norm.append(sum_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_1 = tfidf[0]\n",
    "cos_similarity = []\n",
    "for i in range(5000):\n",
    "    cos = np.dot(tfidf_1,tfidf[i])\n",
    "    cos = cos/norm[0]\n",
    "    cos_similarity.append(cos)\n",
    "for i in range(5000):\n",
    "    dd = norm[i]\n",
    "    cos_similarity[i] = cos_similarity[i]/dd\n",
    "index = [cos_similarity.index(x) for x in sorted(cos_similarity,reverse = True)[:3]]\n",
    "data[index[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangjing/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [cos_similarity.index(x) for x in sorted(cos_similarity,reverse = True)[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beer/ABV': 8.4,\n",
       " 'beer/beerId': '52211',\n",
       " 'beer/brewerId': '14879',\n",
       " 'beer/name': \"Frog's Hollow Double Pumpkin Ale\",\n",
       " 'beer/style': 'Pumpkin Ale',\n",
       " 'review/appearance': 4.0,\n",
       " 'review/aroma': 5.0,\n",
       " 'review/overall': 4.0,\n",
       " 'review/palate': 3.5,\n",
       " 'review/taste': 4.0,\n",
       " 'review/text': 'Poured from a 22oz bottle to a Dogfish Head Snifter.\\t\\tColor: Slight hazy orange with an off white head.\\t\\tSmell: Cinnamon, banana, pumpkin and nutmeg.\\t\\tTaste: Alcohol, pumpkin, nutmeg, allspice and a hint of banana.\\t\\tMouthfeel: Medium carbonation, smooth, medium dryness on the palate.\\t\\tOverall: The smell is GREAT! The banana was a huge surprise for me. The taste had too much alcohol presence. Seemed to overpower the other flavors. Cheers!',\n",
       " 'review/timeStruct': {'hour': 0,\n",
       "  'isdst': 0,\n",
       "  'mday': 14,\n",
       "  'min': 24,\n",
       "  'mon': 11,\n",
       "  'sec': 50,\n",
       "  'wday': 0,\n",
       "  'yday': 318,\n",
       "  'year': 2011},\n",
       " 'review/timeUnix': 1321230290,\n",
       " 'user/profileName': 'Heatwave33'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 8\n",
    "new_feature = []\n",
    "for i in range(5000):\n",
    "    add_c = tfidf[i]\n",
    "    add_c.append(1)\n",
    "    new_feature.append(add_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for tfidf model is:  1.25765745218e-05\n"
     ]
    }
   ],
   "source": [
    "y = [d['review/overall'] for d in data]\n",
    "clf = linear_model.Ridge(1.0,fit_intercept=False)\n",
    "clf.fit(new_feature,y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(new_feature)\n",
    "MSE = 0\n",
    "for i in range(len(y)):\n",
    "    MSE = (y[i]-predictions[i])**2\n",
    "MSE = MSE/len(y)\n",
    "print('MSE for tfidf model is: ',MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#problem 6\n",
    "wordcount1 = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "r = ''.join([c for c in data[0]['review/text'].lower() if not c in punctuation])\n",
    "for w in r.split():\n",
    "    wordcount1[w] += 1\n",
    "wordcount2 = defaultdict(int)\n",
    "r = ''.join([c for c in data[1]['review/text'].lower() if not c in punctuation])\n",
    "for w in r.split():\n",
    "    wordcount2[w] += 1\n",
    "count1 = [(wordcount1[w],w) for w in wordcount1]\n",
    "count2 = [(wordcount2[w],w) for w in wordcount2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordID = dict(zip(range(len(wordset)),wordset)) #index word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in_1 = [x[1] for x in count1]\n",
    "word_in_2 = [x[1] for x in count2]\n",
    "#wordcount1   tf for review1      word , times in review\n",
    "#wordcount2   tf for review2\n",
    "idf_review1 = defaultdict(float)\n",
    "idf_review2 = defaultdict(float)\n",
    "for w in word_in_1:\n",
    "    idf = log10(N/count(w))\n",
    "    idf_review1[w] = idf\n",
    "for w in word_in_2:\n",
    "    idf = log10(N/count(w))\n",
    "    idf_review2[w] = idf\n",
    "tf1 = []                         #tf for review 1\n",
    "for i in range(len(wordset)):\n",
    "    word = wordID[i]\n",
    "    if word in word_in_1:\n",
    "        tf_value = wordcount1[word]\n",
    "        tf1.append(tf_value)\n",
    "    else:\n",
    "        tf1.append(0)\n",
    "tf2 = []                           #tf for review 2\n",
    "for i in range(len(wordset)):\n",
    "    word = wordID[i]\n",
    "    if word in word_in_2:\n",
    "        tf_value = wordcount2[word]\n",
    "        tf2.append(tf_value)\n",
    "    else:\n",
    "        tf2.append(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf1 = []\n",
    "idf2 = []\n",
    "for i in range(len(wordset)):\n",
    "    word = wordID[i]\n",
    "    if word in word_in_1:\n",
    "        idf_value = idf_review1[word]\n",
    "        idf1.append(idf_value)\n",
    "    else:\n",
    "        idf1.append(0)\n",
    "for i in range(len(wordset)):\n",
    "    word = wordID[i]\n",
    "    if word in word_in_2:\n",
    "        idf_value = idf_review2[word]\n",
    "        idf2.append(idf_value)\n",
    "    else:\n",
    "        idf2.append(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tfidf1 = np.array(idf1)*np.array(tf1)\n",
    "tfidf2 = np.array(idf2)*np.array(tf2)\n",
    "tfidf1_list = tfidf1.tolist()\n",
    "tfidf2_list = tfidf2.tolist()\n",
    "sum1 = 0\n",
    "for i in tfidf1_list:\n",
    "    sum1 += i**2\n",
    "sum1 = sum1**(0.5)\n",
    "sum2 = 0\n",
    "for i in tfidf2_list:\n",
    "    sum2 += i**2\n",
    "sum2 = sum2**(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_theta =  0.0658819397474  theta =  0.479013927116 pi\n"
     ]
    }
   ],
   "source": [
    "from math import pi\n",
    "cos = np.dot(tfidf1_list,tfidf2_list)/(sum1*sum2)\n",
    "angle = np.arccos(cos)\n",
    "print('cos_theta = ',cos,' theta = ',angle/pi,'pi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
