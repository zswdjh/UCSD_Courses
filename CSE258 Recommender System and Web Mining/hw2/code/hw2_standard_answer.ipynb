{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parseData(fname):\n",
    "    for l in urlopen(fname):\n",
    "        yield eval(l)\n",
    "\n",
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))\n",
    "print(\"done\")\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [1, datum['review/taste'], datum['review/appearance'], datum['review/aroma'], datum['review/palate'], datum['review/overall']]\n",
    "    return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "y = [d['beer/ABV'] >= 6.5 for d in data]\n",
    "\n",
    "def inner(x,y):\n",
    "    return sum([x[i]*y[i] for i in range(len(x))])\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + exp(-x))\n",
    "\n",
    "##################################################\n",
    "# Logistic regression by gradient ascent         #\n",
    "##################################################\n",
    "\n",
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "    fracPos = sum(y) / len(y)\n",
    "    fracNeg = 1 - fracPos\n",
    "    loglikelihood = 0\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        if y[i]:\n",
    "      #loglikelihood -= 0.5/fracPos * log(1 + exp(-logit)) # balanced\n",
    "          loglikelihood -= log(1 + exp(-logit))\n",
    "        if not y[i]:\n",
    "      #loglikelihood -= 0.5/fracNeg * (log(1 + exp(-logit)) + logit) # balanced\n",
    "          loglikelihood -= (log(1 + exp(-logit)) + logit)\n",
    "    for k in range(len(theta)):\n",
    "        loglikelihood -= lam * theta[k]*theta[k]\n",
    "  # for debugging\n",
    "  # print(\"ll =\" + str(loglikelihood))\n",
    "    return -loglikelihood\n",
    "\n",
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "    fracPos = sum(y) / len(y)\n",
    "    fracNeg = 1 - fracPos\n",
    "    dl = [0]*len(theta)\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        for k in range(len(theta)):\n",
    "            if y[i]:\n",
    "        #dl[k] += 0.5/fracPos * (X[i][k] * (1 - sigmoid(logit))) # balanced\n",
    "            dl[k] += X[i][k] * (1 - sigmoid(logit))\n",
    "            if not y[i]:\n",
    "        #dl[k] += 0.5/fracNeg * (X[i][k] * (1 - sigmoid(logit)) - X[i][k]) # balanced\n",
    "           dl[k] += X[i][k] * (1 - sigmoid(logit)) - X[i][k]\n",
    "    for k in range(len(theta)):\n",
    "        dl[k] -= lam*2*theta[k]\n",
    "    return numpy.array([-x for x in dl])\n",
    "\n",
    "##################################################\n",
    "# Train/validation/test splits                   #\n",
    "##################################################\n",
    "\n",
    "X_train = X[:int(len(X)/3)]\n",
    "y_train = y[:int(len(y)/3)]\n",
    "X_validate = X[int(len(X)/3):int(2*len(X)/3)]\n",
    "y_validate = y[int(len(y)/3):int(2*len(y)/3)]\n",
    "X_test = X[int(2*len(X)/3):]\n",
    "y_test = y[int(2*len(X)/3):]\n",
    "\n",
    "##################################################\n",
    "# Train                                          #\n",
    "##################################################\n",
    "\n",
    "def train(lam):\n",
    "    theta,_,_ = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, pgtol = 10, args = (X_train, y_train, lam))\n",
    "    return theta\n",
    "\n",
    "##################################################\n",
    "# Predict                                        #\n",
    "##################################################\n",
    "\n",
    "def performance(theta, y_train, y_validate, y_test, X_train, X_validate, X_test):\n",
    "                      kkkk\n",
    "                      scores_train = [inner(theta,x) for x in X_train]\n",
    "                      scores_validate = [inner(theta,x) for x in X_validate]\n",
    "                      scores_test = [inner(theta,x) for x in X_test]\n",
    "                      predictions_train = [s > 0 for s in scores_train]\n",
    "                      predictions_validate = [s > 0 for s in scores_validate]\n",
    "                      predictions_test = [s > 0 for s in scores_test]\n",
    "                      correct_train = [(a==b) for (a,b) in zip(predictions_train,y_train)]\n",
    "                      correct_validate = [(a==b) for (a,b) in zip(predictions_validate,y_validate)]\n",
    "                      correct_test = [(a==b) for (a,b) in zip(predictions_test,y_test)]\n",
    "                      acc_train = sum(correct_train) * 1.0 / len(correct_train)\n",
    "                      acc_validate = sum(correct_validate) * 1.0 / len(correct_validate)\n",
    "                      acc_test = sum(correct_test) * 1.0 / len(correct_test)\n",
    "                      TP = sum([(a and b) for (a,b) in zip(predictions_test, y_test)])\n",
    "                      TN = sum([(not a and not b) for (a,b) in zip(predictions_test, y_test)])\n",
    "                      FP = sum([(a and not b) for (a,b) in zip(predictions_test, y_test)])\n",
    "                      FN = sum([(not a and b) for (a,b) in zip(predictions_test, y_test)])\n",
    "                      TPR = TP / (TP + FN)\n",
    "                      TNR = TN / (TN + FP)\n",
    "                      BER = 1.0 - 0.5*(TPR + TNR)\n",
    "                      print(\"BER = \" + str(BER))\n",
    "                      labelsSortedByScore = list(zip(scores_test, y_test))\n",
    "                      labelsSortedByScore.sort()\n",
    "                      labelsSortedByScore.reverse()\n",
    "                      labelsSortedByScore = [a[1] for a in labelsSortedByScore]\n",
    "                      return acc_train, acc_validate, acc_test, (TP, TN, FP, FN, BER), labelsSortedByScore\n",
    "\n",
    "##################################################\n",
    "# Train/validation/test                          #\n",
    "##################################################\n",
    "\n",
    "lam = 1.0\n",
    "theta = train(lam)\n",
    "acc_train, acc_validate, acc_test, _, _ = performance(theta, y_train, y_validate, y_test, X_train, X_validate, X_test)\n",
    "print(\"lambda = \" + str(lam) + \";\\ttrain=\" + str(acc_train) + \"; validate=\" + str(acc_validate) + \"; test=\" + str(acc_test))\n",
    "\n",
    "##################################################\n",
    "# Better features                                #\n",
    "##################################################\n",
    "\n",
    "words = [\"lactic\", \"tart\", \"sour\", \"citric\", \"sweet\", \"acid\", \"hop\", \"fruit\", \"salt\", \"spicy\"]\n",
    "\n",
    "def feature(datum):\n",
    "  text = datum['review/text'].lower()\n",
    "  feat = [1]\n",
    "  for w in words:\n",
    "    feat.append(text.count(w))\n",
    "  return feat\n",
    "\n",
    "X = [feature(d) for d in data]\n",
    "X_train = X[:int(len(X)/3)]\n",
    "X_validate = X[int(len(X)/3):int(2*len(X)/3)]\n",
    "X_test = X[int(2*len(X)/3):]\n",
    "\n",
    "theta = train(lam)\n",
    "acc_train, acc_validate, acc_test, _, _ = performance(theta, y_train, y_validate, y_test, X_train, X_validate, X_test)\n",
    "print(\"lambda = \" + str(lam) + \";\\ttrain=\" + str(acc_train) + \"; validate=\" + str(acc_validate) + \"; test=\" + str(acc_test))\n",
    "\n",
    "##################################################\n",
    "# Error rates                                    #\n",
    "##################################################\n",
    "\n",
    "_, _, _, (TP, TN, FP, FN, BER), labelsSortedByScore = performance(theta, y_train, y_validate, y_test, X_train, X_validate, X_test)\n",
    "\n",
    "print(\"TP = \", TP)\n",
    "print(\"TN = \", TN)\n",
    "print(\"FP = \", FP)\n",
    "print(\"FN = \", FN)\n",
    "print(\"BER = \", BER)\n",
    "\n",
    "##################################################\n",
    "# Validation pipeline                            #\n",
    "##################################################\n",
    "\n",
    "bestLambda = None\n",
    "bestLambdaAcc = None\n",
    "bestValidate = None\n",
    "\n",
    "for lam in [0, 0.01, 1.0, 100.0]:\n",
    "  theta = train(lam)\n",
    "  acc_train, acc_validate, acc_test, _, _ = performance(theta, y_train, y_validate, y_test, X_train, X_validate, X_test)\n",
    "  if (not bestLambda) or acc_validate > bestValidate:\n",
    "    bestLambda = lam\n",
    "    bestValidate = acc_validate\n",
    "    bestLambdaAcc = (acc_train, acc_validate, acc_test)\n",
    "  print(\"lambda = \" + str(lam) + \";\\ttrain=\" + str(acc_train) + \"; validate=\" + str(acc_validate) + \"; test=\" + str(acc_test))\n",
    "\n",
    "print(\"Best lambda on validation set = \" + str(lam))\n",
    "print(\"train/valid/test accuracy = \" + str(bestLambdaAcc))\n",
    "\n",
    "##################################################\n",
    "# PCA                                            #\n",
    "##################################################\n",
    "\n",
    "Xn = [x[1:] for x in X_train] # Drop the offset (shouldn't make a significant difference to answers)\n",
    "Xn = numpy.matrix(Xn)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(Xn)\n",
    "\n",
    "print(pca.components_)\n",
    "\n",
    "##################################################\n",
    "# Replace points by their mean                   #\n",
    "##################################################\n",
    "\n",
    "print(\"Reconstruction error when replacing points by the mean of the corresponding coordinate:\")\n",
    "print(numpy.linalg.norm(Xn - Xn.mean(0))**2) \n",
    "\n",
    "##################################################\n",
    "# Reconstruction error with two dimensions      #\n",
    "##################################################\n",
    "\n",
    "Yn = Xn*pca.components_.T\n",
    "\n",
    "print(\"First transformed data point \" + str(Yn[0]))\n",
    "\n",
    "yVar = numpy.var(Yn,0)\n",
    "print(\"Reconstruction error in the new basis:\")\n",
    "print(len(Yn) * sum(yVar.tolist()[0][2:])) # Reconstruction error\n",
    "\n",
    "##################################################\n",
    "# Plot the PCA dimensions                        #\n",
    "##################################################\n",
    "\n",
    "plt.scatter([a[0,0] for a in Yn], [a[0,1] for a in Yn], color='r')\n",
    "Yn_IPA = [Yn[i] for i in range(len(Yn)) if y[i]]\n",
    "plt.scatter([a[0,0] for a in Yn_IPA], [a[0,1] for a in Yn_IPA], color='b')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
